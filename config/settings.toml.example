project_code = 'OT'
site = 'Oyu Tolgoi'
site_code = 'OT'
network = 'Hugo North Lift 1 Underground Network'
network_code = 'HNL1'

[grids]
  units = 'meter'
  method = 'ODS'
  origin = [650200, 4766170, -500]
  dimensions = [100, 101, 68]
  spacing = 25

  [grids.velocities]
    source = 'local'
    homogeneous = false
    vp = 'velocities/vp'
    vs = 'velocities/vs'
    format = 'NLLOC'

  [grids.travel_time_h5]
   fname = 'travel_time_tables.h5f'

# Not used, definition similar to velocity grids
#[grids.density]
#homogeneous = false

[time_zone]
  type = 'UTC_offset'                # either 'UTC_offset or 'time_zone'
  time_zone_code = 'ULN'             # time zone code. If type=time_zone, time_zone_code must be a valid pytz timezone
  offset = 8                         # time offset in hours, ignored if type=time_zone

[sensors]
  source     = 'local'
  units      = 'meter'
  format     = 'csv'
  path       = 'sensors.csv'
  stationXML = 'OT.xml'
  black_list = ['23', '31', '32', '100', '102', '107', '88', '90', '77']

[data_local]
  ms_chunks = '/home/phil/data/oyu/spp_common/synthetic/chunks/*.mseed'
  ms_10s    = '/home/phil/data/oyu/spp_common/synthetic/simdat10s.mseed'
  xml_10s   = '/home/phil/data/oyu/spp_common/synthetic/simdat10s.xml'

[processing_flow]
# this describes the kafka channel to which the message should be routed
  [processing_flow.automatic]
   trigger_data_name = 'created'
   dataset = 'seismic_event'
   steps = [['nlloc'], ['interloc'], ['picker'], ['nlloc_adjustment'],
            ['measure_amplitudes'], ['magnitude'], ['event_database']
           ]
  [processing_flow.ray_tracing]
   trigger_data_name = 'created'
   dataset = 'seismic_event'
   steps = [['ray_tracer']]

  [processing_flow.interactive]
   steps=[['location'], ['magnitude'], ['event_database', 'ui_notification']]


[data_connector]
  source  = 'remote'
  path    = 'http://10.95.74.35:8002/ims-database-server/databases/mgl'
  # source = 'local'
  # path = '/Users/jpmercier/.spp/data/'
  kafka_consumer_topic = 'data_connector'
  kafka_feedback_topic = 'data_connector'
  kafka_producer_topic =  'picker'
  log_topic = 'data_connector'
  log_file_name = 'data_connector.log'

[initializer]
  log_topic = 'initializer'
  log_file_name = 'initializer.log'
  output_data_name = 'created'
  [initializer.filter]
   freqmin=100
   freqmax=1000
  [initializer.window_size]
   start=-0.3    # seconds before event time
   end=0.9       # seconds after event time

[mseed_decomposer]
  kafka_producer_topic = 'mseed_blocks'

[transformer]
  kafka_consumer_topic = 'mseed_blocks'
  kafka_producer_topic = 'mseed_1sec'

[interloc]
  nthreads = 4
  samplerate_decimated = 3000.0
  fixed_wlen_sec = 2.0
  whiten_corner_freqs = [40.0, 50.0, 350.0, 360.0]
  pair_dist_min = 0.0
  pair_dist_max = 2000.0
  cc_smooth_length_sec = 0.005
  detection_threshold = 0.2
  debug_level = 0
  debug_file_dir = './common'
  output_data_name = 'event_located'
  log_topic = 'interloc'
  log_file_name = 'interloc.log'

[create_event]
  log_topic = 'create_event'
  log_file_name = 'create_event.log'

[picker]
  snr_threshold = 6
  residual_tolerance = 10e-3
  p_s_tolerance = 5e-3  # P and S must be at least separated by p_s_tolerance
  output_data_name  = 'picks_set'
  log_topic = 'automatic picker'
  log_file_name = 'automatic_picker.log'

  [picker.waveform_filter]
    frequency_min = 100
    frequency_max = 1000

  [picker.p_wave]
   [picker.p_wave.search_window]
      start = -20e-3        # start of search window relative to predicted
      arrival time (s)
      end = 5e-3           # end of the search window relative to predicted arrival time (s)
      resolution = 0.001   # time resolution of search window (s)
   [picker.p_wave.snr_window]
      #noise = 0.005         # length of the window for noise energy measurement
      noise = 0.01         # length of the window for noise energy measurement
      signal = 0.01        # length of the window for signal energy measurement

  [picker.s_wave]
    [picker.s_wave.search_window]
      start = -70e-3        # start of search window relative to predicted arrival time (s)
      end = 20e-3           # end of the search window relative to predicted arrival time (s)
      resolution = 0.001   # time resolution of search window (s)
    [picker.s_wave.snr_window]
      #noise = 0.005         # length of the window for noise energy measurement
      #signal = 0.01        # length of the window for signal energy measurement
      noise = 0.01         # length of the window for noise energy measurement
      signal = 0.02        # length of the window for signal energy measurement

[nlloc]
  nll_base = 'NLL'
  locsig = 'Oyu Tolgoi Geotechnical Monitoring Team'
  loccom = 'Prototype'
  residual_tolerance = 10e-3
  # locsearch = 'OCT 20 20 30 1e-6 50000 1000 0 1'
  # locsearch = 'OCT 10 10 10 1e-6 20000 1000 0 1'
  locsearch = 'OCT 5 5 5 1e-6 5000 500 0 1'
  locmeth = 'EDT_OT_WT 9999.0 4 -1 -1 -1 0'
  locgau = ''
  output_data_name = 'hypocenter_location_set'
  log_file_name = 'hypocenter_location_nlloc.log'
  log_topic = 'hypocenter Location NonLinLoc'
  picking_error = 0.001

[nlloc_adjustment]
  nll_base = 'NLL'
  locsig = 'Oyu Tolgoi Geotechnical Monitoring Team'
  loccom = 'Prototype'
  residual_tolerance = 10e-3
  # locsearch = 'OCT 20 20 30 1e-6 50000 1000 0 1'
  # locsearch = 'OCT 10 10 10 1e-6 20000 1000 0 1'
  locsearch = 'OCT 5 5 5 1e-6 5000 500 0 1'
  locmeth = 'EDT_OT_WT 9999.0 4 -1 -1 -1 0'
  locgau = ''
  output_data_name = 'hypocenter_location_adjusted'
  log_file_name = 'hypocenter_location_nlloc.log'
  log_topic = 'hypocenter Location NonLinLoc'
  picking_error = 0.001

[magnitude]
  ttpath = 'None'
  only_triaxial = true
  P_or_S = 'P'
  density = 2700
  use_smom = false
  min_dist = 20
  win_length = 0.02
  # len_spectrum is specified in exponent of 2. For instance 14 is equal to 2 ** 14
  len_spectrum_exponent = 14
  # could instead specify <len_spectrum> directly
  freq = 100
  output_data_name = 'magnitude_set'
  log_file_name = 'magnitude_calculation.log'
  log_topic = 'moment magnitude calculation'

[measure_amplitudes]
  output_data_name = 'amplitude_set'
  log_file_name = 'measure_amplitudes.log'
  log_topic = 'amplitude measurement'

['ray_tracer']
    log_file_name = 'ray_tracer.log'
    log_topic = 'ray_tracer'
    input_kafka_topic = 'ray_tracer'

[kafka]
  brokers = 'broker:9092'
  group_id = 'seismic_processing_platform'
  threads = 3 

[airflow]
  description = 'Data Loader'
  catchup = false

[logging]
  log_directory = '.'
  # log_directory = '/var/log/spp/'
  log_level = 'INFO'
  log_format = '[%(levelname)s] %(asctime)s <%(name)s> <%(thread)d> %(message)s'
  log_filename = 'spp.log'
  logger_name = 'spp'
  log_destination = 'stdout'

[event_database]
  output_data_name = 'saved_to_db'
  log_file_name = 'event_database.log'
  log_topic = 'event database'

[event_db]
  uri = 'mongodb://localhost:27017/'
  name = 'OT'
  trace_collection = 'traces'
  event_collection = 'events'
  events_inuse_collection = 'event_in_use'
  in_use_ttl = 1
  filestore_base_dir = '/var/ot/'
  kafka_topic = 'event_database'
  log_file_name = 'event_db_insertion_update.log'
  log_topic = 'insertion and update into event DB'

[continuous_db]
  uri = 'mongodb://mongo-node-001:27017/'
  db_name = 'seismic'
  traces_collection = 'traces_json'
  events_collection = 'events'
  events_inuse_collection = 'events_inuse'
  filestore_base_dir = '/Users/hanee/Rio_Tinto/data/'
  inuse_ttl = 300

[seismic_api]
  base_url = 'http://api.microquake.org/api/v1/'
  # base_url = 'http://127.0.0.1:8000/api/v1/'

[redis_db]
  # host = 'localhost'
  host = 'redisdb'
  password = ''
  port = 6379
  db = 0

[redis_extra]
  ttl=600

[signal_analysis]
