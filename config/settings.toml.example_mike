project_code = 'OT'

[grids]
  units = 'meter'
  method = 'ODS'
  origin = [650200, 4766170, -500]
  dimensions = [100, 101, 68]
  spacing = 25

  [grids.velocities]
    source = 'local'
    homogeneous = false
    vp = 'velocities/vp'
    vs = 'velocities/vs'
    format = 'NLLOC'

  [grids.travel_time_h5]
   fname = 'travel_time_tables.h5'
   #fname = 'travel_time_tables.h5f'

# Not used, definition similar to velocity grids
#[grids.density]
#homogeneous = false

[time_zone]
  type = 'UTC_offset'                # either 'UTC_offset or 'time_zone'
  time_zone_code = 'ULN'             # time zone code. If type=time_zone, time_zone_code must be a valid pytz timezone
  offset = 8                         # time offset in hours, ignored if type=time_zone

[sensors]
  source     = 'local'
  units      = 'meter'
  format     = 'csv'
  path       = 'sensors.csv'
  stationXML = 'OT.xml'
  black_list = ['23', '31', '32', '100', '102', '107', '88', '90', '77']

[data_local]
  ms_chunks = '/home/phil/data/oyu/spp_common/synthetic/chunks/*.mseed'
  ms_10s    = '/home/phil/data/oyu/spp_common/synthetic/simdat10s.mseed'
  xml_10s   = '/home/phil/data/oyu/spp_common/synthetic/simdat10s.xml'

[processing_flow]
# this describes the kafka channel to which the message should be routed
  [processing_flow.automatic]
   trigger_data_name = 'created'
   dataset = 'seismic_event'
   steps = [['nlloc'], ['interloc'], ['picker'], ['nlloc_adjustment'],
            ['measure_amplitudes'], ['magnitude'], ['event_database']
           ]

  [processing_flow.interactive]
   steps=[['location'], ['magnitude'], ['event_database', 'ui_notification']]


[data_connector]
  source  = 'remote'
  path    = 'http://10.95.74.35:8002/ims-database-server/databases/mgl'
  # source = 'local'
  # path = '/Users/jpmercier/.spp/data/'
  kafka_consumer_topic = 'data_connector'
  kafka_feedback_topic = 'data_connector'
  kafka_producer_topic =  'picker'
  log_topic = 'data_connector'
  log_file_name = 'data_connector.log'

[initializer]
  log_topic = 'initializer'
  log_file_name = 'initializer.log'
  output_data_name = 'created'
  [initializer.filter]
   freqmin=100
   freqmax=1000
  [initializer.window_size]
   start=-0.3    # seconds before event time
   end=0.9       # seconds after event time

[mseed_decomposer]
  kafka_producer_topic = 'mseed_blocks'

[transformer]
  kafka_consumer_topic = 'mseed_blocks'
  kafka_producer_topic = 'mseed_1sec'

[interloc]
  nthreads = 4
  debug = 0
  wlen_sec = 1.0
  dsr = 3000.0
  threshold = 0.2
  output_data_name = 'event_located'
  log_topic = 'interloc'
  log_file_name = 'interloc.log'
  npz_file_dir = './common'

[create_event]
  log_topic = 'create_event'
  log_file_name = 'create_event.log'

[picker]
  snr_threshold = 6
  residual_tolerance = 10e-3
  p_s_tolerance = 5e-3  # P and S must be at least separated by p_s_tolerance
  output_data_name  = 'picks_set'
  log_topic = 'automatic picker'
  log_file_name = 'automatic_picker.log'

  [picker.waveform_filter]
    frequency_min = 100
    frequency_max = 1000

  [picker.p_wave]
   [picker.p_wave.search_window]
      start = -70e-3        # start of search window relative to predicted arrival time (s)
      end = 20e-3           # end of the search window relative to predicted arrival time (s)
      resolution = 0.001   # time resolution of search window (s)
   [picker.p_wave.snr_window]
      #noise = 0.005         # length of the window for noise energy measurement
      noise = 0.01         # length of the window for noise energy measurement
      signal = 0.01        # length of the window for signal energy measurement

  [picker.s_wave]
    [picker.s_wave.search_window]
      start = -70e-3        # start of search window relative to predicted arrival time (s)
      end = 20e-3           # end of the search window relative to predicted arrival time (s)
      resolution = 0.001   # time resolution of search window (s)
    [picker.s_wave.snr_window]
      #noise = 0.005         # length of the window for noise energy measurement
      #signal = 0.01        # length of the window for signal energy measurement
      noise = 0.01         # length of the window for noise energy measurement
      signal = 0.02        # length of the window for signal energy measurement

[nlloc]
  nll_base = 'NLL'
  locsig = 'Oyu Tolgoi Geotechnical Monitoring Team'
  loccom = 'Prototype'
  residual_tolerance = 10e-3
  # locsearch = 'OCT 20 20 30 1e-6 50000 1000 0 1'
  # locsearch = 'OCT 10 10 10 1e-6 20000 1000 0 1'
  locsearch = 'OCT 5 5 5 1e-6 5000 500 0 1'
  locmeth = 'EDT_OT_WT 9999.0 4 -1 -1 -1 0'
  locgau = ''
  output_data_name = 'hypocenter_location_set'
  log_file_name = 'hypocenter_location_nlloc.log'
  log_topic = 'hypocenter Location NonLinLoc'
  picking_error = 0.001

[nlloc_adjustment]
  nll_base = 'NLL'
  locsig = 'Oyu Tolgoi Geotechnical Monitoring Team'
  loccom = 'Prototype'
  residual_tolerance = 10e-3
  # locsearch = 'OCT 20 20 30 1e-6 50000 1000 0 1'
  # locsearch = 'OCT 10 10 10 1e-6 20000 1000 0 1'
  locsearch = 'OCT 5 5 5 1e-6 5000 500 0 1'
  locmeth = 'EDT_OT_WT 9999.0 4 -1 -1 -1 0'
  locgau = ''
  tput_data_name = 'hypocenter_location_adjusted'
  log_file_name = 'hypocenter_location_nlloc.log'
  log_topic = 'hypocenter Location NonLinLoc'
  picking_error = 0.001

[magnitude]
  ttpath = 'None'
  only_triaxial = true
  phase_list = 'P'
  density = 2700
  min_dist = 20
  win_length = 0.02
  # len_spectrum is specified in exponent of 2. For instance 14 is equal to 2 ** 14
  len_spectrum_exponent = 14
  # could instead specify <len_spectrum> directly
  freq = 100
  output_data_name = 'magnitude_set'
  log_file_name = 'magnitude_calculation.log'
  log_topic = 'moment magnitude calculation'
  use_sdr_rad = false
  use_free_surface_correction = false
  make_preferred = true
  [magnitude.smom]
    phase_list = ['P', 'S']
  # If you run freq domain mag mod *after focal mech, and use_sdr_rad is True,
  #    then it will calc/use rad pattern computed for preferred focal mech
    use_sdr_rad = false
    make_preferred = false

[focal_mechanism]
  npolmin = 8
  max_agap = 180
  #max_agap = 90
  max_pgap = 60
  dang = 5
  nmc = 30
  maxout = 500
  badfrac = 0.1
  delmax = 120
  cangle = 45
  prob_max = 0.25
  log_file_name = 'focal_mechanism_calculation.log'
  log_topic = 'focal mechanism calculation'
  plot_focal_mechs = false

[measure_amplitudes]
 # Min thresh params for velocity pulses:
  pulse_min_snr_P = 9
  pulse_min_snr_S = 6
  pulse_min_width = 0.0014
  phase_list = 'P'
 #
  output_data_name = 'amplitude_set'
  log_file_name = 'measure_amplitudes.log'
  log_topic = 'amplitude measurement'

[measure_energy]
  phase_list = ['P', 'S']
  correct_attenuation = false
  attenuation_Q = 200
  use_sdr_rad = false

[measure_smom]
  phase_list = ['P', 'S']
  S_win_len = 0.1
  pre_window_start_sec = 0.01
  max_S_P_time = 0.25
  use_fixed_fmin_fmax = false
 # These are only used if use_fixed_fmin_fmax = true:
  fmin = 30.0
  fmax = 600.0

[kafka]
  brokers = 'broker:9092'
  group_id = 'seismic_processing_platform'
  threads = 3 

[airflow]
  description = 'Data Loader'
  catchup = false

[logging]
  log_directory = '.'
  # log_directory = '/var/log/spp/'
  log_level = 'INFO'
  log_format = '[%(levelname)s] %(asctime)s <%(name)s> <%(thread)d> %(message)s'
  log_filename = 'spp.log'
  logger_name = 'spp'
  log_destination = 'stdout'

[event_database]
  output_data_name = 'saved_to_db'
  log_file_name = 'event_database.log'
  log_topic = 'event database'

[event_db]
  uri = 'mongodb://localhost:27017/'
  name = 'OT'
  trace_collection = 'traces'
  event_collection = 'events'
  events_inuse_collection = 'event_in_use'
  in_use_ttl = 1
  filestore_base_dir = '/var/ot/'
  kafka_topic = 'event_database'
  log_file_name = 'event_db_insertion_update.log'
  log_topic = 'insertion and update into event DB'

[continuous_db]
  uri = 'mongodb://mongo-node-001:27017/'
  db_name = 'seismic'
  traces_collection = 'traces_json'
  events_collection = 'events'
  events_inuse_collection = 'events_inuse'
  filestore_base_dir = '/Users/hanee/Rio_Tinto/data/'
  inuse_ttl = 300

[seismic_api]
  base_url = 'http://api.microquake.org/api/v1/'
  # base_url = 'http://127.0.0.1:8000/api/v1/'

[redis_db]
  # host = 'localhost'
  host = 'redisdb'
  password = ''
  port = 6379
  db = 0

[redis_extra]
  ttl=600

